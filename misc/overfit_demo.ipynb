{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b483afb-0086-4842-ad54-3829ae375239",
   "metadata": {},
   "source": [
    "# overfit_demo.ipynb\n",
    "# WESmith 06/27/23\n",
    "## Demonstrate underfittig/overfitting of simple functions using pytorch\n",
    "## using some techniques from\n",
    "### https://pytorch.org/tutorials/beginner/pytorch_with_examples.html?highlight=polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2e75a-2abd-439b-837e-4da4df7bf79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy    as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd51a3-3270-4172-b790-2edba7b5df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim         = 1.0\n",
    "npts        = 1000\n",
    "max_order   = 7 # maximum polynomial order to use\n",
    "noise_scale = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4251d-439d-471c-9971-8be80fe1baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max = (-lim, lim) #(-0.1, 0.1)  # x limits\n",
    "x = torch.linspace(min, max, npts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b4ed5-35f1-4d23-9b5a-d983cdde15b2",
   "metadata": {},
   "source": [
    "## POLYNOMIAL BASIS USED TO CREATE DATA AND TO FIT THE NOISY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b83c11-329c-493e-828c-a9f5afc8b0be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p  = torch.tensor(range(max_order + 1))\n",
    "xx = x.unsqueeze(-1).pow(p)  # important to turn (npts) vector into (npts,1) vector for this to work\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.plot(x, xx)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a7e91-adbb-4ecd-a665-fca82c63140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed here if desired\n",
    "coeffs  = torch.randn(max_order + 1)\n",
    "y       = xx @ coeffs  # clean random signal using polynomial basis\n",
    "train   = y + noise_scale * torch.randn(npts)  # noisy signal\n",
    "test    = y + noise_scale * torch.randn(npts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9473b85-406c-4132-aadf-95d62a261207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, y,     'r',  label='original polynomial')\n",
    "plt.plot(x, train, 'b.', label='training data')\n",
    "plt.plot(x, test,  'g.', label='testing data')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151843e8-58cf-4edc-8d1c-a65d9c044a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model uses the fixed polynomial basis as input: it is just estimating\n",
    "# the max_order + 1 unknown polynomial coefficients\n",
    "# turn off bias in NN, since constant term is in polynomial\n",
    "# this is a one-neuron model, with max_order + 1 inputs to the neuron\n",
    "# this is pure classical linear regression using SGD instead of algebraic (AT*A)^-1 * AT\n",
    "model = nn.Sequential(nn.Linear(max_order + 1, 1, bias=False), nn.Flatten(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09da89c-24cf-4e5e-8d3e-163ce4619449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanation of model dimensions:\n",
    "# (n_samples, max_order + 1) input array x ((max_order + 1) x 1) array to be trained = (n_samples x 1)\n",
    "# nn.Flatten(0, 1) transforms (n_samples x 1) array into (n_samples) array output\n",
    "# nn.Flatten(start_dim, end_dim) multiplies start_dim x intermediate_dims x end_dim to flatten that range\n",
    "# see nn.Flatten? examples\n",
    "#nn.Flatten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32759c81-74e0-4890-82f1-f8e57c670c37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(n_iter, model, train, target, test=None, lr=1e-3, print_iter=100):\n",
    "    # 'test', if input, is a tuple: (test_data, test_target)\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    loss_fn   = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    for t in range(n_iter):\n",
    "        y_pred = model(train)\n",
    "        loss   = loss_fn(y_pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if t % print_iter == 0:\n",
    "            if test is None:\n",
    "                print(f'iter: {t:5}, train: {loss.item():10.3f}')\n",
    "            else:\n",
    "                with torch.no_grad(): # make sure gradients aren't affected\n",
    "                    test_pred = model(test[0])\n",
    "                    loss_test = loss_fn(test_pred, test[1])\n",
    "                print(f'iter: {t:5}, train: {loss.item():10.3f}, test: {loss_test.item():10.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55a60a-4e9b-40e1-9ce0-7d026ce95b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.MSELoss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0131551-d5a0-4a96-ad4f-490a688a1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx is the FIXED polynomial basis, the model() contains the learned poly coefficients\n",
    "# NOTE that this isn't the usual paradigm for NN training: normally the training set\n",
    "# is input to the model, and the target is compared to the predictions; here the training\n",
    "# set IS the target, and the training set is the xx, the fixed polynomial basis\n",
    "# ie, here xx = training, train = target\n",
    "train_model(10001, model, xx, train, test=test, lr=1e-3, print_iter=500)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd00cbdd-ba7d-4c57-85a0-0acb24f8f38a",
   "metadata": {},
   "source": [
    "dd = model(xx)\n",
    "dd.shape, train.shape, xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35d767-980a-4f46-9264-7f0261cd4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5), sharex=False)\n",
    "xvals = np.arange(len(coeffs))\n",
    "ax1.plot(xvals, coeffs, 'ro', label='true coeffs')\n",
    "ax1.plot(xvals, model[0].weight.squeeze().detach().numpy(), 'bo', label='estimated coeffs')\n",
    "ax1.grid()\n",
    "ax1.set_title('True and Estimated Polynomial Coefficients')\n",
    "ax1.legend()\n",
    "ax2.plot(x, y, 'r', label='true polynomial')\n",
    "ax2.plot(x, model(xx).detach().numpy(), 'b', label='estimated polynomial')\n",
    "ax2.grid()\n",
    "ax2.set_title('True and Estimated Polynomial')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d46705-ff04-4f2d-ac5d-02e629c89d35",
   "metadata": {},
   "source": [
    "## FIT POLYNOMIAL TO SINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d20a61b-3756-47fd-ab30-9bf0c9a45528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sine():\n",
    "    '''\n",
    "    npts  = number of points to evaluate sine over x = (-1, 1) interval\n",
    "    freq  = cycles per (0, 1) x-axis interval (ie, NOT (-1, 1) interval), can be fractional\n",
    "    amp   = amplitude of sine (default 1.0)\n",
    "    phase = shift in DEGREES independent of frequency: positive shifts to the right\n",
    "            ie: a shift in -90 deg will turn the sine into a cosine regardless of frequency\n",
    "            (default 0.0 deg)\n",
    "    NOTE: keeping x-axis from -1 to 1 for stability in neural-net applications\n",
    "    NOTE2: \n",
    "    '''\n",
    "    def __init__(self, npts, freq, amp=1.0, phase=0.0):\n",
    "        self.npts  = npts\n",
    "        self.freq  = freq\n",
    "        self.amp   = amp\n",
    "        self.phase = phase  # in degrees\n",
    "        rad_phase  = phase * math.pi / 180\n",
    "        self.x     = torch.linspace(-1.0, 1.0, npts)\n",
    "        self.scale = 2.0 * math.pi * freq\n",
    "        self.out   = amp * torch.sin(self.scale * self.x - rad_phase)\n",
    "\n",
    "    def plot(self, polyfit=False, wid=14, hei=4):\n",
    "        # polyfit = number of the polynomial fit (int)\n",
    "        # polynomial fitting is only accurate for phase = 0.0\n",
    "        if polyfit:\n",
    "            self.sine_coeffs(polyfit + 1)\n",
    "            p  = torch.tensor(range(polyfit + 1))\n",
    "            xx = self.x.unsqueeze(-1).pow(p)  # create the polynomial basis\n",
    "            y  = self.amp * xx @ self.coeffs  # matrix multiply  (N x polyfit) * (polyfit x 1)\n",
    "        fig, ax = plt.subplots(figsize=(wid, hei))\n",
    "        ax.plot(self.x, self.out, 'b', label=f'sin(2*pi*{self.freq}*x)')\n",
    "        if polyfit:\n",
    "            ax.plot(self.x, y, 'r', label=f'polynomial fit with {polyfit} terms')\n",
    "        ax.grid()\n",
    "        ax.set_aspect('auto')\n",
    "        ax.autoscale(enable=True, tight=True)\n",
    "        ax.set_ylim(-2.0, 2.0)\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.x, self.out\n",
    "    \n",
    "    def sine_coeffs(self, n):\n",
    "        # convenience function to get the 'n' Taylor sine coefficients scaled to the frequency\n",
    "        coeffs = torch.zeros(n)\n",
    "        v = 1\n",
    "        for i in range(n):\n",
    "            if i % 2 == 1:\n",
    "                coeffs[i] = v * self.scale**i / np.math.factorial(i)\n",
    "                v *= -1\n",
    "        self.coeffs = coeffs\n",
    "        return self.coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf225d-ac88-4821-abf5-4e19884fae6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd = Sine(1000, 5, amp=1.5, phase=0)\n",
    "dd.plot(polyfit=31, wid=10,hei=3)\n",
    "x, y = dd()\n",
    "coeffs = dd.sine_coeffs(31)\n",
    "x.shape, y.shape, coeffs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6c5b124-7abd-4de5-a3f3-668ef4ac3a34",
   "metadata": {},
   "source": [
    "def get_sine_coeffs(length):  # courtesy chatgpt\n",
    "    coeffs = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        if i % 2 == 0:\n",
    "            coeffs[i] = 0\n",
    "        else:\n",
    "            coeffs[i] = (-1) ** ((i-1)//2) / np.math.factorial(i)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db6ede-2e33-496d-94f2-dd7941eeb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "npts        = 1000\n",
    "max_order   = 7 # maximum polynomial order to use\n",
    "noise_scale = 1.0\n",
    "freq        = 1.0 # sine freq\n",
    "#sine_coeffs = torch.tensor(get_sine_coeffs(max_order + 1), dtype=torch.float32)\n",
    "dd = Sine(npts, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39959cf8-6c42-42f5-b5d4-bc414ccb3d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd.plot(max_order, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6812c07-37fd-469d-b49e-d568c9f117d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x = torch.linspace(-limit * math.pi, limit * math.pi, npts)\n",
    "x, ysin = dd()\n",
    "sine_coeffs = dd.sine_coeffs(max_order + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bace3d4-af25-48a5-8d31-f5ea03bce4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fb26f-6e68-47b4-a977-f59f9a9a499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p  = torch.tensor(range(max_order + 1))\n",
    "xx = x.unsqueeze(-1).pow(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a91d1f-d970-4def-b59b-3d5ee3662822",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33efeb3b-96ad-4842-a765-5c04584bdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ysin = torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b74e4-1393-4e34-b69d-7dcb44c6b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same linear-regression model as above\n",
    "model   = nn.Sequential(nn.Linear(max_order + 1, 1, bias=False), nn.Flatten(0, 1))\n",
    "lr      = 1e-3  # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40fea94-ec04-448a-b780-36a5078ccbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_model(n_iter, model, train, target, test, lr=1e-3, print_iter=100):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20800c2-f43a-41b3-89a0-8b99a109de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(60001, model, xx, ysin, lr=1e-2, print_iter=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95656ba2-201e-4680-b4a0-46a604f24972",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharex=False)\n",
    "xvals = np.arange(max_order + 1)\n",
    "ax1.plot(xvals, sine_coeffs, 'go', label='true coeffs')\n",
    "ax1.plot(xvals, model[0].weight.squeeze().detach().numpy(), 'ro', label='estimated coeffs')\n",
    "ax1.grid()\n",
    "ax1.set_title('True and Estimated Polynomial Coefficients')\n",
    "ax1.legend()\n",
    "ax2.plot(x, ysin, '#BBBBBB', linewidth=10.0, label='exact sine')\n",
    "ax2.plot(x, xx @ sine_coeffs, 'g', label='limited-Taylor-poly sine')\n",
    "ax2.plot(x, model(xx).detach().numpy(), 'r', label='model-estimated sine')\n",
    "ax2.set_ylim(-2.0, 2.0)\n",
    "ax2.grid()\n",
    "ax2.set_title('True and Estimated Coefficients')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b5463-bf09-4d9d-a514-ea7bcf1c9313",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NEURAL NET TO SINE: NO POLYNOMIAL BASIS IS USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe8c0e-8983-47ef-ab13-245e600f4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n1, n2): # n1, n2 are the sizes of the layers\n",
    "        super().__init__()\n",
    "        # ReLU produced jagged results fitting the sine, Tanh much smoother\n",
    "        self.stack = nn.Sequential(nn.Linear(1, n1), \n",
    "                                   nn.Tanh(),  # Tanh works well for this problem\n",
    "                                   nn.Linear(n1, n2),\n",
    "                                   nn.Tanh(),  # Tanh works well for this problem\n",
    "                                   nn.Linear(n2, 1))\n",
    "                                   # do not want a nonlinearity at the end of this regressiion model\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stack(x).squeeze()\n",
    "        return x\n",
    "    \n",
    "    def num_params(self):  # WS addition\n",
    "        count = 0\n",
    "        for k in self.parameters():\n",
    "            count += k.numel()\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48dade4-dc0a-4d7a-928d-3788741b4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "npts        = 2000\n",
    "freq        = 3.0 # sine freq\n",
    "dd = Sine(npts, freq)\n",
    "x, target = dd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681fa1b0-c093-472e-9444-1b7ce6383f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.plot(13, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe860b-4ba8-4005-a9bc-9c8fa56c88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = NeuralNet(50, 30) # 30, 30 works well so far\n",
    "print(new_model.num_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb26834-f5d8-4750-9e57-28fa8997bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.view(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08069316-8a4d-4463-808e-fa40f6d85cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(20001, new_model, x.view(-1,1), target, lr=1e-3, print_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cf8a1-e547-43eb-9390-61c24b5e5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 6), sharex=False)\n",
    "ax1.plot(x.numpy(), target.numpy(), '#BBBBBB', linewidth=10.0, label='true sine')\n",
    "ax1.plot(x.numpy(), new_model(x.view(-1,1)).detach().numpy(), 'r', label='estimated sine')\n",
    "ax1.grid()\n",
    "ax1.set_title('True and Estimated Sine')\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf2a84-d744-482c-8124-775c54f1ef3a",
   "metadata": {},
   "source": [
    "### TRAIN ON A RANDOM SET OF X VALUES, COMPARE LOSS FROM NON-TRAINING X VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0c706-a7fc-42c5-95c9-be8c84caf5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "npts        = 1000\n",
    "freq        = 4.0 # sine freq\n",
    "dd = Sine(npts, freq)\n",
    "x, target = dd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247bb49e-a937-4069-9f37-be9b7110772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.plot(13, 4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51bcff0-a0b2-4c20-bd89-3b0e4ebffb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get random x values and associated target values\n",
    "train_frac = 0.02\n",
    "total_samp = len(x)\n",
    "indices = torch.randperm(total_samp)\n",
    "cutoff = int(total_samp * train_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a78b6-91d0-4ceb-b204-6dd64f340aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[indices[:cutoff]]\n",
    "y_train = target[indices[:cutoff]]\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8bd794-7ff8-40d1-a460-64958b39e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x[indices[cutoff:]]\n",
    "y_test = target[indices[cutoff:]]\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12f0859-8919-4336-ad3f-6db2261222de",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = NeuralNet(30, 30) # 30, 30 works well so far\n",
    "print(new_model.num_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc175131-c841-4d2f-ad2a-c9e0536b6f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = (x_test.view(-1,1), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2c0ed-dbb7-481c-95bd-bc896b6e7999",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(20001, new_model, x_train.view(-1,1), y_train, test=test, lr=1e-3, print_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ed1ac-750c-40d8-bd9d-2c32f34a5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 6), sharex=False)\n",
    "ax1.plot(x.numpy(), target.numpy(), '#CCCCCC', linewidth=10.0, label='true sine')\n",
    "ax1.plot(x_train.numpy(), new_model(x_train.view(-1,1)).detach().numpy(), 'ro', label='estimate from training')\n",
    "ax1.plot(x_test.numpy(), new_model(x_test.view(-1,1)).detach().numpy(), 'g.', label='estimate from test')\n",
    "ax1.grid()\n",
    "ax1.set_title('Overfitting Example From overfit_demo.ipynb')\n",
    "ax1.legend()\n",
    "plt.savefig('overfit.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
