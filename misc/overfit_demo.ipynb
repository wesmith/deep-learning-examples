{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b483afb-0086-4842-ad54-3829ae375239",
   "metadata": {},
   "source": [
    "# overfit_demo.ipynb\n",
    "# WESmith 06/27/23\n",
    "## Demonstrate underfittig/overfitting of simple functions using pytorch\n",
    "## using some techniques from\n",
    "### https://pytorch.org/tutorials/beginner/pytorch_with_examples.html?highlight=polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a2e75a-2abd-439b-837e-4da4df7bf79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy    as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd51a3-3270-4172-b790-2edba7b5df17",
   "metadata": {},
   "outputs": [],
   "source": [
    "lim         = 1.0\n",
    "npts        = 1000\n",
    "max_order   = 7 # maximum polynomial order to use\n",
    "noise_scale = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f4251d-439d-471c-9971-8be80fe1baa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min, max = (-lim, lim) #(-0.1, 0.1)  # x limits\n",
    "x = torch.linspace(min, max, npts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18b4ed5-35f1-4d23-9b5a-d983cdde15b2",
   "metadata": {},
   "source": [
    "## POLYNOMIAL BASIS USED TO CREATE DATA AND TO FIT THE NOISY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b83c11-329c-493e-828c-a9f5afc8b0be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p  = torch.tensor(range(max_order + 1))\n",
    "xx = x.unsqueeze(-1).pow(p)  # important to turn (npts) vector into (npts,1) vector for this to work\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.plot(x, xx)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499a7e91-adbb-4ecd-a665-fca82c63140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed here if desired\n",
    "coeffs  = torch.randn(max_order + 1)\n",
    "y       = xx @ coeffs  # clean random signal using polynomial basis\n",
    "train   = y + noise_scale * torch.randn(npts)  # noisy signal\n",
    "test    = y + noise_scale * torch.randn(npts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9473b85-406c-4132-aadf-95d62a261207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.plot(x, y,     'r',  label='original polynomial')\n",
    "plt.plot(x, train, 'b.', label='training data')\n",
    "plt.plot(x, test,  'g.', label='testing data')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151843e8-58cf-4edc-8d1c-a65d9c044a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model uses the fixed polynomial basis as input: it is just estimating\n",
    "# the max_order + 1 unknown polynomial coefficients\n",
    "# turn off bias in NN, since constant term is in polynomial\n",
    "# this is a one-neuron model, with max_order + 1 inputs to the neuron\n",
    "# this is pure classical linear regression using SGD instead of algebraic (AT*A)^-1 * AT\n",
    "model = nn.Sequential(nn.Linear(max_order + 1, 1, bias=False), nn.Flatten(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09da89c-24cf-4e5e-8d3e-163ce4619449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanation of model dimensions:\n",
    "# (n_samples, max_order + 1) input array x ((max_order + 1) x 1) array to be trained = (n_samples x 1)\n",
    "# nn.Flatten(0, 1) transforms (n_samples x 1) array into (n_samples) array output\n",
    "# nn.Flatten(start_dim, end_dim) multiplies start_dim x intermediate_dims x end_dim to flatten that range\n",
    "# see nn.Flatten? examples\n",
    "#nn.Flatten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32759c81-74e0-4890-82f1-f8e57c670c37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(n_iter, model, train, target, test=None, lr=1e-3, print_iter=100):\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    loss_fn   = nn.MSELoss(reduction='sum')\n",
    "    for t in range(n_iter):\n",
    "        y_pred = model(train)\n",
    "        loss   = loss_fn(y_pred, target)\n",
    "        if t % print_iter == 0:\n",
    "            if test is None:\n",
    "                print(f'iter: {t:5}, train: {loss.item():10.3f}')\n",
    "            else:\n",
    "                with torch.no_grad(): # make sure gradients aren't affected\n",
    "                    loss_test = loss_fn(y_pred, test)\n",
    "                print(f'iter: {t:5}, train: {loss.item():10.3f}, test: {loss_test.item():10.3f}')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0131551-d5a0-4a96-ad4f-490a688a1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx is the FIXED polynomial basis, the model() contains the learned poly coefficients\n",
    "# NOTE that this isn't the usual paradigm for NN training: normally the training set\n",
    "# is input to the model, and the target is compared to the predictions; here the training\n",
    "# set IS the target, and the training set is the xx, the fixed polynomial basis\n",
    "# ie, here xx = training, train = target\n",
    "train_model(10001, model, xx, train, test=test, lr=1e-3, print_iter=500)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd00cbdd-ba7d-4c57-85a0-0acb24f8f38a",
   "metadata": {},
   "source": [
    "dd = model(xx)\n",
    "dd.shape, train.shape, xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b35d767-980a-4f46-9264-7f0261cd4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5), sharex=False)\n",
    "xvals = np.arange(len(coeffs))\n",
    "ax1.plot(xvals, coeffs, 'ro', label='true coeffs')\n",
    "ax1.plot(xvals, model[0].weight.squeeze().detach().numpy(), 'bo', label='estimated coeffs')\n",
    "ax1.grid()\n",
    "ax1.set_title('True and Estimated Polynomial Coefficients')\n",
    "ax1.legend()\n",
    "ax2.plot(x, y, 'r', label='true polynomial')\n",
    "ax2.plot(x, model(xx).detach().numpy(), 'b', label='estimated polynomial')\n",
    "ax2.grid()\n",
    "ax2.set_title('True and Estimated Polynomial')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d46705-ff04-4f2d-ac5d-02e629c89d35",
   "metadata": {},
   "source": [
    "## FIT POLYNOMIAL TO SINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d20a61b-3756-47fd-ab30-9bf0c9a45528",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sine():\n",
    "    '''\n",
    "    npts  = number of points to evaluate sine over x = (-1, 1) interval\n",
    "    freq  = cycles per (0, 1) x-axis interval (ie, NOT (-1, 1) interval), can be fractional\n",
    "    amp   = amplitude of sine (default 1.0)\n",
    "    phase = shift in DEGREES independent of frequency: positive shifts to the right\n",
    "            ie: a shift in -90 deg will turn the sine into a cosine regardless of frequency\n",
    "            (default 0.0 deg)\n",
    "    NOTE: keeping x-axis from -1 to 1 for stability in neural-net applications\n",
    "    NOTE2: \n",
    "    '''\n",
    "    def __init__(self, npts, freq, amp=1.0, phase=0.0):\n",
    "        self.npts  = npts\n",
    "        self.freq  = freq\n",
    "        self.amp   = amp\n",
    "        self.phase = phase  # in degrees\n",
    "        rad_phase  = phase * math.pi / 180\n",
    "        self.x     = torch.linspace(-1.0, 1.0, npts)\n",
    "        self.scale = 2.0 * math.pi * freq\n",
    "        self.out   = amp * torch.sin(self.scale * self.x - rad_phase)\n",
    "\n",
    "    def plot(self, polyfit=False, wid=14, hei=4):\n",
    "        # polyfit = number of the polynomial fit (int)\n",
    "        # polynomial fitting is only accurate for phase = 0.0\n",
    "        if polyfit:\n",
    "            self.sine_coeffs(polyfit + 1)\n",
    "            p  = torch.tensor(range(polyfit + 1))\n",
    "            xx = self.x.unsqueeze(-1).pow(p)  # create the polynomial basis\n",
    "            y  = self.amp * xx @ self.coeffs  # matrix multiply  (N x polyfit) * (polyfit x 1)\n",
    "        fig, ax = plt.subplots(figsize=(wid, hei))\n",
    "        ax.plot(self.x, self.out, 'b', label=f'sin(2*pi*{self.freq}*x)')\n",
    "        if polyfit:\n",
    "            ax.plot(self.x, y, 'r', label=f'polynomial fit with {polyfit} terms')\n",
    "        ax.grid()\n",
    "        ax.set_aspect('auto')\n",
    "        ax.autoscale(enable=True, tight=True)\n",
    "        ax.set_ylim(-2.0, 2.0)\n",
    "        plt.tight_layout()\n",
    "        plt.legend()\n",
    "        \n",
    "    def __call__(self):\n",
    "        return self.x, self.out\n",
    "    \n",
    "    def sine_coeffs(self, n):\n",
    "        # convenience function to get the 'n' Taylor sine coefficients scaled to the frequency\n",
    "        coeffs = torch.zeros(n)\n",
    "        v = 1\n",
    "        for i in range(n):\n",
    "            if i % 2 == 1:\n",
    "                coeffs[i] = v * self.scale**i / np.math.factorial(i)\n",
    "                v *= -1\n",
    "        self.coeffs = coeffs\n",
    "        return self.coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cf225d-ac88-4821-abf5-4e19884fae6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd = Sine(1000, 5, amp=1.5, phase=0)\n",
    "dd.plot(polyfit=31, wid=10,hei=3)\n",
    "x, y = dd()\n",
    "coeffs = dd.sine_coeffs(31)\n",
    "x.shape, y.shape, coeffs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6c5b124-7abd-4de5-a3f3-668ef4ac3a34",
   "metadata": {},
   "source": [
    "def get_sine_coeffs(length):  # courtesy chatgpt\n",
    "    coeffs = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        if i % 2 == 0:\n",
    "            coeffs[i] = 0\n",
    "        else:\n",
    "            coeffs[i] = (-1) ** ((i-1)//2) / np.math.factorial(i)\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03db6ede-2e33-496d-94f2-dd7941eeb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "npts        = 1000\n",
    "max_order   = 7 # maximum polynomial order to use\n",
    "noise_scale = 1.0\n",
    "freq        = 1.0 # sine freq\n",
    "#sine_coeffs = torch.tensor(get_sine_coeffs(max_order + 1), dtype=torch.float32)\n",
    "dd = Sine(npts, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39959cf8-6c42-42f5-b5d4-bc414ccb3d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd.plot(max_order, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6812c07-37fd-469d-b49e-d568c9f117d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#x = torch.linspace(-limit * math.pi, limit * math.pi, npts)\n",
    "x, ysin = dd()\n",
    "sine_coeffs = dd.sine_coeffs(max_order + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bace3d4-af25-48a5-8d31-f5ea03bce4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fb26f-6e68-47b4-a977-f59f9a9a499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p  = torch.tensor(range(max_order + 1))\n",
    "xx = x.unsqueeze(-1).pow(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a91d1f-d970-4def-b59b-3d5ee3662822",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33efeb3b-96ad-4842-a765-5c04584bdce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ysin = torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b74e4-1393-4e34-b69d-7dcb44c6b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same linear-regression model as above\n",
    "model   = nn.Sequential(nn.Linear(max_order + 1, 1, bias=False), nn.Flatten(0, 1))\n",
    "lr      = 1e-3  # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40fea94-ec04-448a-b780-36a5078ccbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_model(n_iter, model, train, target, test, lr=1e-3, print_iter=100):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20800c2-f43a-41b3-89a0-8b99a109de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(60001, model, xx, ysin, lr=1e-2, print_iter=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95656ba2-201e-4680-b4a0-46a604f24972",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharex=False)\n",
    "xvals = np.arange(max_order + 1)\n",
    "ax1.plot(xvals, sine_coeffs, 'go', label='true coeffs')\n",
    "ax1.plot(xvals, model[0].weight.squeeze().detach().numpy(), 'ro', label='estimated coeffs')\n",
    "ax1.grid()\n",
    "ax1.set_title('True and Estimated Polynomial Coefficients')\n",
    "ax1.legend()\n",
    "ax2.plot(x, ysin, '#BBBBBB', linewidth=10.0, label='exact sine')\n",
    "ax2.plot(x, xx @ sine_coeffs, 'g', label='limited-Taylor-poly sine')\n",
    "ax2.plot(x, model(xx).detach().numpy(), 'r', label='model-estimated sine')\n",
    "ax2.set_ylim(-2.0, 2.0)\n",
    "ax2.grid()\n",
    "ax2.set_title('True and Estimated Coefficients')\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b5463-bf09-4d9d-a514-ea7bcf1c9313",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NEURAL NET TO SINE: NO POLYNOMIAL BASIS IS USED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397b9ab-6aa6-453a-859d-e26ab9f74703",
   "metadata": {},
   "outputs": [],
   "source": [
    "npts        = 1000\n",
    "noise_scale = 0.01\n",
    "limit       = 2.0\n",
    "batch_size  = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe8c0e-8983-47ef-ab13-245e600f4593",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n1, n2): # n1, n2 are the sizes of the layers\n",
    "        super().__init__()\n",
    "        # ReLU produced jagged results fitting the sine, Tanh much smoother\n",
    "        self.stack = nn.Sequential(nn.Linear(1, n1), \n",
    "                                   nn.Tanh(),\n",
    "                                   nn.Linear(n1, n2),\n",
    "                                   # do not want a nonlinearity at the end of this regressiion model\n",
    "                                   nn.Tanh(),\n",
    "                                   nn.Linear(n2, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.stack(x).squeeze()\n",
    "        return x\n",
    "    \n",
    "    def num_params(self):  # WS addition\n",
    "        count = 0\n",
    "        for k in self.parameters():\n",
    "            count += k.numel()\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c7070d-0b02-4dc4-9ac3-04f0be98469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up torch Dataset object for the DataLoader\n",
    "class SineData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, limit, npts, noise_scale=0.0):\n",
    "        super().__init__()\n",
    "        # x is the training set: each value of x is like a 1-parameter feature\n",
    "        # use view() to add singleton dimension to x\n",
    "        self.x     = torch.linspace(-limit * math.pi, limit * math.pi, npts).view(-1, 1)\n",
    "        self.targ  = torch.sin(self.x).squeeze() + noise_scale * torch.randn(npts)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.targ[idx]\n",
    "    \n",
    "    def plot(self): # WS addition\n",
    "        fig = plt.figure()\n",
    "        plt.plot(self.x.numpy(), self.targ.numpy(), 'b.')\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df280568-09c7-41bd-a942-0282d98f7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = SineData(limit, npts, noise_scale)\n",
    "test_data  = SineData(limit, npts, noise_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2949892-37c3-487e-8417-5faa971a8a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96034c-44b9-4613-900c-952547a10985",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6d351-381f-42f1-a44f-7e486f7b5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa8b18d-1c10-418e-9ef8-fed3da623fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader  = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ec765f-eb53-47db-bab5-c6b1c4786889",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k in enumerate(train_loader):\n",
    "#    print(k[0], k[1][0].shape, k[1][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91440265-0600-433d-928c-1232684e8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d1, d2 = next(iter(test_loader))\n",
    "#d1.T, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da77a909-d6a5-44d6-a543-dd8945f4a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_batch(model, train_loader, test_loader=None, epoch=0, print_iter=3, lr=1e-3, pp=False):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "    loss_fn   = nn.MSELoss(reduction='sum')\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        y_pred = model(data)\n",
    "        loss   = loss_fn(y_pred, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        txt = f'epoch: {epoch:4}, batch: {batch_idx:4}, train: {loss.item():10.3f}'\n",
    "        if batch_idx % print_iter == 0 and pp:\n",
    "            if test_loader is None:\n",
    "                print(txt)\n",
    "            else:\n",
    "                with torch.no_grad(): # make sure gradients aren't affected\n",
    "                    # target_loader will run out before test_loader since this\n",
    "                    # called only periodically (assuming test batch size <= train batch size)\n",
    "                    (test_data, test_target) = next(iter(test_loader))\n",
    "                    y_pred    = model(test_data)\n",
    "                    loss_test = loss_fn(y_pred, test_target)\n",
    "                print(txt + f', test: {loss_test.item():10.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe860b-4ba8-4005-a9bc-9c8fa56c88c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = NeuralNet(10, 10)\n",
    "lr = 1e-3\n",
    "print(new_model.num_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db53e2f-e71f-4516-96a1-0a7759a64a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(500):\n",
    "    update = True if k % 50 == 0 else False\n",
    "    train_with_batch(new_model, train_loader, test_loader=None,\n",
    "                     epoch=k, print_iter=15, lr=1e-4, pp=update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cf8a1-e547-43eb-9390-61c24b5e5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 6), sharex=False)\n",
    "x = train_data.x\n",
    "ax1.plot(x.numpy(), torch.sin(x).squeeze(),        'r', label='true sine')\n",
    "ax1.plot(x.numpy(), new_model(x).detach().numpy(), 'b', label='estimated sine')\n",
    "ax1.grid()\n",
    "ax1.set_title('True and Estimated Sine')\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8deeb8-a3bf-41b1-a439-8f94b17286be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
